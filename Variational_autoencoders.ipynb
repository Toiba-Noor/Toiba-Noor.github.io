{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "from torch import nn,optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 784])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4, 20])\n"
     ]
    }
   ],
   "source": [
    "## input_img >- hidden dim >- mean,std >- Parametrization trick >- decoder >- output_img\n",
    "class VariationalAutoEndocers(nn.Module):\n",
    "    def __init__(self,input_dim,h_dim = 200,z_dim = 20):\n",
    "        super(VariationalAutoEndocers,self).__init__()\n",
    "        # for encoder\n",
    "        self.img_2hid = nn.Linear(input_dim,h_dim)\n",
    "        self.hid_2mu = nn.Linear(h_dim,z_dim)\n",
    "        self.hid_2sigma = nn.Linear(h_dim,z_dim)\n",
    "        # for decoder\n",
    "        self.z_2hid = nn.Linear(z_dim,h_dim)\n",
    "        self.hid_2img = nn.Linear(h_dim,input_dim)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def encode(self,x):\n",
    "        ## TODO: Define the encoder q_phi(z|x)\n",
    "        h = self.relu(self.img_2hid(x))\n",
    "        mu = self.hid_2mu(h)\n",
    "        sigma = self.hid_2sigma(h)\n",
    "        return mu,sigma\n",
    "\n",
    "    def decode(self,z):\n",
    "        ## TODO: Define the decoder p_theta(x|z)\n",
    "        h = self.relu(self.z_2hid(z))\n",
    "        x = torch.sigmoid(self.hid_2img(h)) ## to ensure the value of the image is between 0 and 1 because of it being a pixel value for MNIST\n",
    "        return x\n",
    "\n",
    "    def forward(self,x):\n",
    "        mu,sigma = self.encode(x)\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z_reparametrized = mu + sigma*epsilon ## reparametrization trick to sample from the latent space z i.e it pushes it towards the gaussian distribution and hence bring sampling into the loop of backpropagation\n",
    "        x_reconstructed = self.decode(z_reparametrized)\n",
    "        return x_reconstructed,mu,sigma\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn(4,784) ## batch size of 4, each have a size of 28*28\n",
    "    vae = VariationalAutoEndocers(input_dim = 784)\n",
    "    x_reconstructed,mu,sigma = vae(x)\n",
    "    print(x_reconstructed.shape)\n",
    "    print(mu.shape)\n",
    "    print(sigma.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_DIM = 784\n",
    "H_DIM = 200\n",
    "Z_DIM = 20\n",
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset\n",
    "dataset = datasets.MNIST(root = \"dataset/\",train = True,transform = transforms.ToTensor(),download = True) ## the transform normalizes the data to be between 0 and 1 by dividing by 255\n",
    "train_loader = DataLoader(dataset = dataset,batch_size = BATCH_SIZE,shuffle = True)\n",
    "model = VariationalAutoEndocers(input_dim = INPUT_DIM,h_dim = H_DIM,z_dim = Z_DIM).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(),lr = LEARNING_RATE)\n",
    "loss_fnc = nn.BCELoss(reduction = \"sum\") ## reduction = \"sum\" because we want to sum the loss over all the pixels in the image, this loss works not only for binary values nut also for float values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:06, 276.31it/s, loss=1.88e+4]\n",
      "1875it [00:06, 278.27it/s, loss=1.85e+4]\n",
      "1875it [00:06, 279.56it/s, loss=1.8e+4] \n",
      "1875it [00:06, 277.24it/s, loss=1.75e+4]\n",
      "1875it [00:06, 277.88it/s, loss=1.7e+4] \n",
      "1875it [00:06, 280.85it/s, loss=1.62e+4]\n",
      "1875it [00:06, 278.91it/s, loss=1.56e+4]\n",
      "1875it [00:06, 275.56it/s, loss=1.45e+4]\n",
      "1875it [00:06, 276.31it/s, loss=1.36e+4]\n",
      "1875it [00:06, 277.60it/s, loss=1.31e+4]\n",
      "1875it [00:06, 274.94it/s, loss=1.19e+4]\n",
      "1875it [00:06, 276.68it/s, loss=1.12e+4]\n",
      "1875it [00:06, 276.66it/s, loss=1.05e+4]\n",
      "1875it [00:06, 276.09it/s, loss=1e+4]   \n",
      "1875it [00:06, 272.92it/s, loss=9.61e+3]\n",
      "1875it [00:06, 273.65it/s, loss=9.02e+3]\n",
      "1875it [00:06, 272.58it/s, loss=9.32e+3]\n",
      "1875it [00:06, 273.47it/s, loss=8.86e+3]\n",
      "1875it [00:06, 273.57it/s, loss=8.38e+3]\n",
      "1875it [00:06, 270.03it/s, loss=8.32e+3]\n",
      "1875it [01:17, 24.34it/s, loss=8e+3]    \n",
      "1875it [04:37,  6.76it/s, loss=8.96e+3] \n",
      "1875it [00:07, 261.40it/s, loss=8.3e+3] \n",
      "1875it [00:07, 255.24it/s, loss=8.56e+3]\n",
      "1875it [00:06, 269.68it/s, loss=8.21e+3]\n",
      "1875it [00:06, 270.40it/s, loss=8.32e+3]\n",
      "1875it [00:06, 269.90it/s, loss=8.78e+3]\n",
      "1875it [00:07, 262.23it/s, loss=7.95e+3]\n",
      "1875it [00:06, 293.73it/s, loss=7.4e+3] \n",
      "1875it [00:06, 289.25it/s, loss=7.97e+3]\n",
      "1875it [00:07, 250.13it/s, loss=7.75e+3]\n",
      "1875it [00:06, 275.61it/s, loss=7.41e+3]\n",
      "1875it [00:06, 279.80it/s, loss=7.48e+3]\n",
      "1875it [00:06, 303.35it/s, loss=7.76e+3]\n",
      "1875it [00:06, 283.63it/s, loss=7.98e+3]\n",
      "1875it [00:07, 265.10it/s, loss=7.81e+3]\n",
      "1875it [00:06, 272.48it/s, loss=7.58e+3]\n",
      "1875it [00:06, 293.82it/s, loss=7.68e+3]\n",
      "1875it [00:06, 297.16it/s, loss=7.72e+3]\n",
      "1875it [00:06, 287.56it/s, loss=7.39e+3]\n",
      "1875it [00:06, 276.91it/s, loss=7.32e+3]\n",
      "1875it [00:06, 281.55it/s, loss=7.43e+3]\n",
      "1875it [00:07, 267.08it/s, loss=7.84e+3]\n",
      "1875it [00:06, 290.43it/s, loss=7.47e+3]\n",
      "1875it [00:06, 293.76it/s, loss=7.53e+3]\n",
      "1875it [00:06, 299.70it/s, loss=7.65e+3]\n",
      "1875it [00:06, 307.54it/s, loss=7.94e+3]\n",
      "1875it [00:06, 303.39it/s, loss=7.19e+3]\n",
      "1875it [00:06, 307.27it/s, loss=7.75e+3]\n",
      "1875it [00:06, 296.96it/s, loss=7.67e+3]\n",
      "1875it [00:06, 298.51it/s, loss=7.29e+3]\n",
      "1875it [00:07, 263.95it/s, loss=7.3e+3] \n",
      "1875it [00:06, 290.39it/s, loss=7.5e+3] \n",
      "1875it [00:06, 295.13it/s, loss=7.48e+3]\n",
      "1875it [00:06, 305.66it/s, loss=7.66e+3]\n",
      "1875it [00:06, 302.60it/s, loss=7.84e+3]\n",
      "1875it [00:06, 308.79it/s, loss=7.16e+3]\n",
      "1875it [00:07, 263.94it/s, loss=6.9e+3] \n",
      "1875it [00:07, 263.08it/s, loss=7.05e+3]\n",
      "1875it [00:06, 274.24it/s, loss=7.61e+3]\n",
      "1875it [00:05, 315.79it/s, loss=6.94e+3]\n",
      "1875it [00:06, 308.07it/s, loss=7.4e+3] \n",
      "1875it [00:05, 313.51it/s, loss=7.83e+3]\n",
      "1875it [00:06, 310.05it/s, loss=7.18e+3]\n",
      "1875it [00:06, 308.94it/s, loss=7.08e+3]\n",
      "1875it [00:06, 309.23it/s, loss=7.31e+3]\n",
      "1875it [00:06, 307.97it/s, loss=6.81e+3]\n",
      "1875it [00:06, 309.30it/s, loss=6.87e+3]\n",
      "1875it [00:06, 308.64it/s, loss=7.12e+3]\n",
      "1875it [00:06, 309.69it/s, loss=7.16e+3]\n",
      "1875it [00:06, 309.49it/s, loss=7.12e+3]\n",
      "1875it [00:06, 310.64it/s, loss=6.93e+3]\n",
      "1875it [00:05, 314.87it/s, loss=6.77e+3]\n",
      "1875it [00:06, 307.38it/s, loss=7.41e+3]\n",
      "1875it [00:05, 312.85it/s, loss=7.14e+3]\n",
      "1875it [00:06, 310.96it/s, loss=6.87e+3]\n",
      "1875it [00:05, 313.25it/s, loss=6.62e+3]\n",
      "1875it [00:06, 307.75it/s, loss=6.75e+3]\n",
      "1875it [00:06, 308.97it/s, loss=6.52e+3]\n",
      "1875it [00:06, 306.32it/s, loss=7.03e+3]\n",
      "1875it [00:06, 309.56it/s, loss=7.26e+3]\n",
      "1875it [00:06, 310.13it/s, loss=6.94e+3]\n",
      "1875it [00:06, 306.50it/s, loss=6.86e+3]\n",
      "1875it [00:06, 308.83it/s, loss=6.34e+3]\n",
      "1875it [00:06, 300.01it/s, loss=6.49e+3]\n",
      "1875it [00:06, 303.55it/s, loss=6.51e+3]\n",
      "1875it [00:06, 307.33it/s, loss=6.36e+3]\n",
      "1875it [00:06, 306.78it/s, loss=6.85e+3]\n",
      "1875it [00:06, 306.89it/s, loss=6.53e+3]\n",
      "1875it [00:06, 300.89it/s, loss=6.72e+3]\n",
      "1875it [00:06, 295.38it/s, loss=6.82e+3]\n",
      "1875it [00:06, 306.79it/s, loss=6.03e+3]\n",
      "1875it [00:06, 299.70it/s, loss=6.64e+3]\n",
      "1875it [00:06, 308.83it/s, loss=6.49e+3]\n",
      "1875it [00:06, 308.24it/s, loss=6.19e+3]\n",
      "1875it [00:06, 302.14it/s, loss=6.65e+3]\n",
      "1875it [00:06, 287.79it/s, loss=6.45e+3]\n",
      "1875it [00:07, 259.26it/s, loss=6.67e+3]\n",
      "1875it [00:06, 275.86it/s, loss=6.41e+3]\n",
      "1875it [00:07, 265.54it/s, loss=6.04e+3]\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "for epoch in range(N_EPOCHS):\n",
    "    loop = tqdm(enumerate(train_loader)) ## tqdm is a progress bar , its comes with a enumerate function which gives the index of the batch and the batch itself, also tqdm comes from the arabic word \"taqaddum\" which means progress\n",
    "    for batch_idx,(x,_) in loop:\n",
    "        x = x.to(DEVICE)\n",
    "        x = x.view(x.shape[0],INPUT_DIM) ## flattening the image ## data.shape[0] is the batch size ## data.shape[1] is the number of channels ## data.shape[2] is the height of the image ## data.shape[3] is the width of the image ## In this case view will do the same thing as reshape but it is more efficient as it does not copy the data\n",
    "        x_reconstructed,mu,sigma = model(x)\n",
    "\n",
    "        ## Reconstruction loss\n",
    "        reconstruction_loss = loss_fnc(x_reconstructed,x) ## already a minus sign in the loss for minimization\n",
    "        kl_d = 0.5*torch.sum(mu**2 + sigma**2 - torch.log(sigma**2) - 1) ## KL divergence\n",
    "        #kl_divergence = -(torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))/2) ## it will push it towards the standard guassian\n",
    "\n",
    "        ## Backpropagation\n",
    "        loss = reconstruction_loss + kl_d\n",
    "        optimizer.zero_grad() ## No accumulated gradient from before\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(loss = loss.item()) ##set_postfix is a function of tqdm which will show the loss in the progress bar\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inferencing\n",
    "def inference(digit, num_examples):\n",
    "    \"\"\"\n",
    "    Generates (num_examples) of a particular digit.\n",
    "    Specifically we extract an example of each digit,\n",
    "    then after we have the mu, sigma representation for\n",
    "    each digit we can sample from that.\n",
    "\n",
    "    After we sample we can run the decoder part of the VAE\n",
    "    and generate examples.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    idx = 0\n",
    "    for x, y in dataset:\n",
    "        if y == idx:\n",
    "            images.append(x)\n",
    "            idx += 1\n",
    "        if idx == 10:\n",
    "            break\n",
    "\n",
    "    encodings_digit = []\n",
    "    for d in range(10):\n",
    "        with torch.no_grad():\n",
    "            mu, sigma = model.encode(images[d].view(1, 784))\n",
    "        encodings_digit.append((mu, sigma))\n",
    "\n",
    "    mu, sigma = encodings_digit[digit]\n",
    "    for example in range(num_examples):\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z = mu + sigma * epsilon\n",
    "        out = model.decode(z)\n",
    "        out = out.view(-1, 1, 28, 28)\n",
    "        save_image(out, f\"generated_{digit}_ex{example}.png\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Inference\n",
    "inference(0, 10)\n",
    "\n",
    "## print the image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('generated_0_ex0.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
